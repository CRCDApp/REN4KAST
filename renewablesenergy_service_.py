# -*- coding: utf-8 -*-
"""RenewablesEnergy_Service.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1bE50o9uxZReZo-IhCJ8Ms20mbYHZMvK9

# 1.   Gathering Data and Save into a CSV File

#connecting to drive
"""

"""### merging data sets and then up sampling"""

import datetime


import tensorflow as tf
import multiprocessing as mp



"""# TRYING DIFFERENT EXOGENOUS PARAMETERS

"""

print(tf.test.gpu_device_name())
print("cpu count", mp.cpu_count())
PATH = "/content/drive/My Drive/"  # @param {type:"string"}
data_path = "/content/drive/My Drive/walk-forward-results/MODELSFORPLOT/"  # @param {type:"string"}

from datetime import datetime, timedelta
import sys
import numpy as np, pandas as pd
from statsmodels.graphics.tsaplots import plot_acf, plot_pacf
from sklearn import metrics
from math import sqrt
import matplotlib.pyplot as plt
import dateutil.parser
import ast
import pandas as pd
import matplotlib.pyplot as plt
from statsmodels.tsa.stattools import adfuller  # to do ADF test
from statsmodels.graphics.tsaplots import plot_acf, plot_pacf
from statsmodels.tsa.arima_model import ARIMA  # to do predictions
from sklearn.model_selection import train_test_split
# from sklearn.utils import check_arrays

import requests, io
import json
import os
from pandas import read_csv
import pandas as pd
from datetime import datetime
from matplotlib import pyplot
from matplotlib import pyplot as PLT
from statsmodels.tsa.arima_model import ARIMA
from statsmodels.tsa.statespace.sarimax import SARIMAX  # ,SARIMAXParams,SARIMAXSpecification,SARIMAXResults
from sklearn.metrics import mean_squared_error
from statsmodels.tsa.seasonal import seasonal_decompose
from sklearn import metrics
from google.colab import drive

drive.mount('/content/drive')


def read_and_split_data(target_period_days=3, start_date="2019-07-01 01:00:00", days_to_test=1,
                        exog_columns=['temperature', 'dewpoint', 'humidity', 'windspeed', 'winddirection', 'pressure'],
                        file_name='twoWeeks'):
    data = pd.read_csv(PATH + '{}.csv'.format(file_name), index_col=0)
    data.index = pd.date_range(start=data.index[0], periods=len(data), freq='15Min')
    # rengeneration = pd.read_csv('/content/drive/My Drive/generationOnly.csv', index_col=0)
    # rengeneration.index = pd.date_range(start=data.index[0], periods=len(rengeneration), freq='15Min')
    # data['renewablespercentage'] = rengeneration["percentage"][:len(data)]

    # starting the data from the mentioned day
    data = data[data.index >= dateutil.parser.parse(start_date)]
    # only considering the target period of days, 24 hours per day and 4 observations per hour
    data = data.iloc[:int(target_period_days * 24 * 4), :]
    # calculating number of test data 24 hours per day and 4 observations per hour
    test_size = days_to_test * 24 * 4
    train_size = int(data.shape[0] - test_size)
    train, test = data.renewablespercentage[0:train_size], data.renewablespercentage[train_size:]
    # selecting defined columns for exog parameters
    exog_train, exog_test = data[0:train_size].iloc[:, [data.columns.get_loc(ex) for ex in exog_columns]], data[
                                                                                                           train_size:].iloc[
                                                                                                           :, [
                                                                                                               data.columns.get_loc(
                                                                                                                   ex)
                                                                                                               for ex in
                                                                                                               exog_columns]]
    # old way
    # exog_train,exog_test = data[0:train_size].loc[:, exog_columns], data[train_size:].loc[:, exog_columns]
    # print(test)
    return train, test, exog_train, exog_test, data


# create a set of sarima configs to try
def sarima_configs(t_params=['n', 'c', 't', 'ct']):
    models = list()
    # define config lists
    p_params = [i for i in range(4)]  # 12
    d_params = [i for i in range(3)]  # 4
    q_params = [i for i in range(4)]  # 12
    # t_params = ['ct']#['n','c','t','ct']
    P_params = [i for i in range(3)]  # 4
    D_params = [i for i in range(2)]  # 2
    Q_params = [i for i in range(3)]  # 4
    m_params = [4]  # weeks-months-seasons per year
    # create config instances
    for p in p_params:
        for d in d_params:
            for q in q_params:
                for t in t_params:
                    for P in P_params:
                        for D in D_params:
                            for Q in Q_params:
                                for m in m_params:
                                    cfg = [(p, d, q), (P, D, Q, m), t]
                                    # we use string to remove compare and remove the configs that have been executed already
                                    models.append(str(cfg))
    return models


def print_describe_residuals(resid, filename='qasd0078.txt'):
    with open(PATH + '{}'.format(filename), 'a+') as f:
        print("----------RESIDUALS----------", file=f)
        print(resid.describe(), file=f)
    f.close()


def save_photo(test, actual, outputname):
    fig = PLT.figure(num=None, figsize=(25, 10), dpi=80, facecolor='w', edgecolor='k')

    #######################
    '''   plt.plot(total_test_sarimax, label='Actual')
    plt.plot(fc_series_sarimax, label='Forecast-SARIMAX')
    plt.plot(fc_series_sarima, label='Forecast-SARIMA')
    plt.plot(fc_series_arimax, label='Forecast-ARIMAX')
    plt.title('Forecast vs Actuals',fontsize=font_size)
    plt.legend(loc='upper left')
    plt.xlabel('Time [YYYY-MM-DD]', fontsize=font_size)
    plt.ylabel('Percentage of the Renewables [%]', fontsize=font_size)
    plt.savefig(data_path + 'PLOT-TEST-ONLY{}.png'.format(output_file_name), format='png', dpi=1200)
    plt.show()
    plt.close(fig)
    '''
    ######################

    PLT.plot(test.index, test, test.index, actual, '-')

    # PLT.title('Forecast vs Actuals',fontsize=font_size)
    # PLT.legend(loc='upper left')
    # PLT.xlabel('Time [YYYY-MM-DD]', fontsize=font_size)
    # PLT.ylabel('Percentage of the Renewables [%]', fontsize=font_size)

    PLT.savefig(PATH + '{}.png'.format(outputname))
    # PLT.close()
    PLT.close(fig)


def print_model_into_file(modelFit, output):
    with open(PATH + '{}'.format(output), 'a+') as f:
        print(modelFit.summary(), file=f)
    f.close()


def mean_absolute_percentage_error(y_true, y_pred):
    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100


def mean_percentage_error(y_true, y_pred):
    return np.mean((y_true - y_pred) / y_true) * 100


def mean_error(y_true, y_pred):
    return np.mean(y_true - y_pred)


def print_evaluation_metrics(test, prediction, label, outputname):
    with open(PATH + '{}'.format(outputname), 'a+') as f:
        print("-----------------{}-----------------".format(label), file=f)
        print("MSE", metrics.mean_squared_error(test, prediction), file=f)
        print("RMSE", sqrt(metrics.mean_squared_error(test, prediction)), file=f)
        print("MAE", metrics.mean_absolute_error(test, prediction), file=f)
        print("MAPE", mean_absolute_percentage_error(test, prediction), '%', file=f)
        print("MPE", mean_percentage_error(test, prediction), '%', file=f)
        print("mean Error", mean_error(test, prediction), file=f)
        print("R2S", metrics.r2_score(test, prediction), file=f)

    f.close()


def run_and_save_SARIMAX_model(train, test, exog_train, exog_test, config, output):
    order, sorder, trend = config
    model = SARIMAX(train, order=order, seasonal_order=sorder, trend=trend, exog=exog_train)
    model_fit = model.fit()
    residuals = model_fit.resid
    predict = model_fit.forecast(len(test), exog=exog_test)
    yhat = model_fit.predict()
    print_model_into_file(model_fit, '{}.txt'.format(output))
    save_photo(train, yhat, '{}-train--{}'.format(output, config))
    save_photo(test, predict, '{}-test-{}'.format(output, config))
    print_evaluation_metrics(train, yhat, "TRAIN", '{}.txt'.format(output))
    print_evaluation_metrics(test, predict, "TEST", '{}.txt'.format(output))
    print_describe_residuals(residuals, '{}.txt'.format(output))
    return model_fit, predict


def run_and_save_SARIMA_model(train, test, config, output):
    order, sorder, trend = config
    model = SARIMAX(train, order=order, seasonal_order=sorder, trend=trend)
    model_fit = model.fit()
    residuals = model_fit.resid
    predict = model_fit.forecast(len(test))
    yhat = model_fit.predict()
    print_model_into_file(model_fit, '{}.txt'.format(output))
    save_photo(train, yhat, '{}-train--{}'.format(output, config))
    save_photo(test, predict, '{}-test-{}'.format(output, config))
    print_evaluation_metrics(train, yhat, "TRAIN", '{}.txt'.format(output))
    print_evaluation_metrics(test, predict, "TEST", '{}.txt'.format(output))
    print_describe_residuals(residuals, '{}.txt'.format(output))
    return model_fit, predict


class summaryDto:
    def __init__(self, aic, summary):
        self.aic = aic
        self.summary = summary


def getAIC(summaryDTO):
    return summaryDTO.aic


def write_bests_to_file(output, summaries):
    with open(PATH + '{}.txt'.format(output), 'w+') as f:
        for m in summaries:
            print(m.summary, file=f)
            print(m.aic, file=f)
            # (m.summary)
    f.close()


def read_old_configs(old_configs_file_name):
    try:
        f = open(PATH + '{}.txt'.format(old_configs_file_name), 'r')
        lines = f.readlines()
        f.close()
        return lines
    except:
        f = open(PATH + '{}.txt'.format(old_configs_file_name), 'a+')
        f.close()
        return []


def updating_old_configs_file(old_configs_file_name, cfg):
    with open(PATH + '{}.txt'.format(old_configs_file_name), 'a+') as f:
        print(cfg, file=f)
    f.close()


def writing_model_execution_time(old_configs_file_name, time):
    with open(PATH + '{}-TIMES.txt'.format(old_configs_file_name), 'a+') as f:
        print(time, file=f)
    f.close()


def writing_total_execution_time(old_configs_file_name, time):
    with open(PATH + '{}TOTAL-times.txt'.format(old_configs_file_name), 'a+') as f:
        print(time, file=f)
    f.close()


def write_models_by_AIC(model_summaries, model_fit, size):
    try:
        model_summaries.sort(reverse=True, key=getAIC)
        if (len(model_summaries) > size):
            # model_summaries.sort(reverse=True, key=getAIC)
            model_summaries[0] = summaryDto(model_fit.aic, model_fit.summary())
        else:
            model_summaries.append(summaryDto(model_fit.aic, model_fit.summary()))
            # print(model_summaries)
        model_summaries.sort(reverse=True, key=getAIC)
        write_bests_to_file(output_file_name + "TOP_MODELS", model_summaries)
        return model_summaries
    except:
        print("Error in writing AIC")


def write_top_models_by_measure(model_summaries, model_summary_DTO, size, output_file_name):
    try:
        model_summaries.sort(reverse=True, key=getAIC)
        if (len(model_summaries) > size):
            # model_summaries.sort(reverse=True, key=getAIC)
            model_summaries[0] = model_summary_DTO
        else:
            model_summaries.append(model_summary_DTO)
            # print(model_summaries)
        model_summaries.sort(reverse=True, key=getAIC)
        write_bests_to_file(output_file_name + "TOP_MODELS", model_summaries)
        return model_summaries
    except:
        print("Error in writing " + label)


def walk_forward(output_file_name, config, old_configs_file_name, number_of_top_models, target_period_days,
                 days_to_test, start_date, dataset_name, exog_columns):
    with tf.device('/device:GPU:0'):
        total_test = pd.Series()
        total_predict = pd.Series()
        # creating the new folder path

        try:
            path = PATH + "walk-forward-results/" + str(config)
            print(path)
            os.mkdir(path)
        except OSError:
            print("ERROR Creation of the directory %s failed" % path)
        else:
            print("Successfully created the directory %s " % path)
        # splitting data and creating the model
        try:
            path = PATH + "walk-forward-results/" + str(config) + "/images"
            print(path)
            os.mkdir(path)
        except OSError:
            print("ERROR Creation of the directory %s failed" % path)
        else:
            print("Successfully created the directory %s " % path)
        try:
            for walking_parameter in range(1, days_to_test + 1):
                train, test, exog_train, exog_test, data = read_and_split_data(
                    target_period_days=target_period_days + walking_parameter, start_date=start_date, days_to_test=1,
                    exog_columns=exog_columns, file_name=dataset_name)
                # print(train.head) print(test.head)
                # print(train)

                model_fit, predict = run_and_save_SARIMAX_model(train, test, exog_train, exog_test, config,
                                                                "walk-forward-results/" + str(
                                                                    config) + '/' + output_file_name + str(
                                                                    config) + "DAY" + str(walking_parameter))
                print(config, walking_parameter)
                total_test = total_test.append(test)
                total_predict = total_predict.append(predict)
                # print("test\n",type(predict))
                # print("total predict\n",len(total_predict))
            # print("total test", total_test)
            # print("total predict", total_predict)
            fig = PLT.figure(num=None, figsize=(25, 10), dpi=80, facecolor='w', edgecolor='k')
            PLT.plot(total_test.index, total_test, total_test.index, total_predict, '-')
            PLT.savefig(PATH + "walk-forward-results/" + str(config) + '/images/{}.png'.format(output_file_name))
            PLT.close(fig)

            # intra day MPE, MAE interday
            error_avg = 0
            meanError = 0
            meanRMSE = 0
            meanMSE = 0
            meanMAE = 0
            meanMAPE = 0
            meanMPE = 0
            meanR2S = 0
            data_frequency_per_day = 96
            for day in range(days_to_test):
                error_avg += abs(
                    mean_percentage_error(total_test[day * data_frequency_per_day:(day + 1) * data_frequency_per_day],
                                          total_predict[
                                          day * data_frequency_per_day:(day + 1) * data_frequency_per_day]))
                meanError += abs(
                    mean_error(total_test[day * data_frequency_per_day:(day + 1) * data_frequency_per_day],
                               total_predict[
                               day * data_frequency_per_day:(day + 1) * data_frequency_per_day]))
                meanRMSE += abs(
                    sqrt(metrics.mean_squared_error(
                        total_test[day * data_frequency_per_day:(day + 1) * data_frequency_per_day],
                        total_predict[
                        day * data_frequency_per_day:(day + 1) * data_frequency_per_day])))

                meanMSE += abs(
                    metrics.mean_squared_error(
                        total_test[day * data_frequency_per_day:(day + 1) * data_frequency_per_day],
                        total_predict[
                        day * data_frequency_per_day:(day + 1) * data_frequency_per_day]))

                meanMAE += abs(
                    metrics.mean_absolute_error(
                        total_test[day * data_frequency_per_day:(day + 1) * data_frequency_per_day],
                        total_predict[
                        day * data_frequency_per_day:(day + 1) * data_frequency_per_day]))

                meanMAPE += abs(
                    mean_absolute_percentage_error(
                        total_test[day * data_frequency_per_day:(day + 1) * data_frequency_per_day],
                        total_predict[
                        day * data_frequency_per_day:(day + 1) * data_frequency_per_day]))

                meanMPE += abs(
                    mean_percentage_error(total_test[day * data_frequency_per_day:(day + 1) * data_frequency_per_day],
                                          total_predict[
                                          day * data_frequency_per_day:(day + 1) * data_frequency_per_day]))

                meanR2S += abs(
                    metrics.r2_score(total_test[day * data_frequency_per_day:(day + 1) * data_frequency_per_day],
                                     total_predict[
                                     day * data_frequency_per_day:(day + 1) * data_frequency_per_day]))

            with open(PATH + "walk-forward-results/" + str(config) + '/{}.txt'.format(output_file_name), 'a+') as f:
                print("-----------------{}-----------------".format(str(config)), file=f)
                print("MSE", metrics.mean_squared_error(total_test, total_predict), file=f)
                print("RMSE", sqrt(metrics.mean_squared_error(total_test, total_predict)), file=f)
                print("MAE", metrics.mean_absolute_error(total_test, total_predict), file=f)
                print("MAPE", mean_absolute_percentage_error(total_test, total_predict), '%', file=f)
                print("MPE", mean_percentage_error(total_test, total_predict), '%', file=f)
                print("R2S", metrics.r2_score(total_test, total_predict), file=f)
                print("Intra Day MPE, Inter day MAE", error_avg / days_to_test, file=f)
                print("MeanError", meanError / days_to_test, file=f)
                print("------------------", file=f)

                print("meanRMSE", meanRMSE / days_to_test, file=f)
                print("meanMSE", meanMSE / days_to_test, file=f)
                print("meanMAE", meanMAE / days_to_test, file=f)
                print("meanMAPE", meanMAPE / days_to_test, file=f)
                print("meanMPE", meanMPE / days_to_test, file=f)
                print("meanR2S", meanR2S / days_to_test, file=f)

            f.close()
            return model_fit, total_test, total_predict, train
        except:
            print("\n\n\n\nError in walk forward\n\n\n\n")
            print("Unexpected error:", sys.exc_info()[0])


def run_forward_all_models(output_file_name, config, old_configs_file_name, number_of_top_models, days_to_test,
                           target_period_days, start_date, dataset_name):
    model_summaries_AIC = []
    model_summaries_MPE = []
    model_summaries_RMSE = []
    model_summaries_MAPE = []
    model_summaries_MAE = []
    model_summaries_intra_MPE = []
    total_exectuion_time = timedelta()
    data_frequency_per_day = 96  # 24 hours * 4 freq/hour
    try:
        path = PATH + "walk-forward-results/" + "MODELSFORPLOT"
        print(path)
        os.mkdir(path)
    except OSError:
        print("ERROR Creation of the directory %s failed" % path)

    for cfg in config:
        try:
            start = datetime.now()
            model_fit, total_test, total_predict, train = walk_forward(output_file_name=output_file_name,
                                                                       config=cfg,
                                                                       old_configs_file_name=old_configs_file_name,
                                                                       number_of_top_models=number_of_top_models,
                                                                       days_to_test=days_to_test,
                                                                       target_period_days=target_period_days,
                                                                       start_date=start_date, dataset_name=dataset_name,
                                                                       exog_columns=exog_columns)
        except:
            print("following model was skiped:", str(cfg))

        try:
            model_summaries_MPE = write_top_models_by_measure(model_summaries_MPE, summaryDto(
                np.abs(mean_percentage_error(total_test, total_predict)), model_fit.summary()),
                                                              number_of_top_models,
                                                              "walk-forward-results/" + output_file_name + "--MPE-")
            model_summaries_RMSE = write_top_models_by_measure(model_summaries_RMSE, summaryDto(
                sqrt(metrics.mean_squared_error(total_test, total_predict)), model_fit.summary()),
                                                               number_of_top_models,
                                                               "walk-forward-results/" + output_file_name + "--RMSE-")
            model_summaries_MAPE = write_top_models_by_measure(model_summaries_MAPE, summaryDto(
                np.abs(mean_absolute_percentage_error(total_test, total_predict)), model_fit.summary()),
                                                               number_of_top_models,
                                                               "walk-forward-results/" + output_file_name + "--MAPE-")
            model_summaries_MAE = write_top_models_by_measure(model_summaries_MAE, summaryDto(
                np.abs(metrics.mean_absolute_error(total_test, total_predict)), model_fit.summary()),
                                                              number_of_top_models,
                                                              "walk-forward-results/" + output_file_name + "--MAE-")

            # intra day MPE, MAE interday
            error_avg = 0
            for day in range(days_to_test):
                error_avg += abs(
                    mean_percentage_error(
                        total_test[day * data_frequency_per_day:(day + 1) * data_frequency_per_day],
                        total_predict[
                        day * data_frequency_per_day:(day + 1) * data_frequency_per_day]))
            model_summaries_intra_MPE = write_top_models_by_measure(model_summaries_intra_MPE,
                                                                    summaryDto(error_avg / days_to_test,
                                                                               model_fit.summary()),
                                                                    number_of_top_models,
                                                                    "walk-forward-results/" + output_file_name + "--INTRA Day MPE- INTER Day MAe-")

            fc_series = pd.Series(total_predict, index=total_test.index)
            # lower_series = pd.Series(conf[:, 0], index=total_test.index)
            # upper_series = pd.Series(conf[:, 1], index=total_test.index)

            # Plot
            fig = plt.figure(figsize=(12, 5), dpi=100)
            plt.plot(train, label='training')
            plt.plot(total_test, label='actual')
            plt.plot(fc_series, label='forecast')
            # plt.fill_between(lower_series.index, lower_series, upper_series,
            #                 color='k', alpha=.15)
            plt.title('Forecast vs Actuals')
            plt.legend(loc='upper left', fontsize=8)
            plt.savefig(PATH + "walk-forward-results/" + str(cfg) + '/images/{}TRAINTEST.png'.format(output_file_name),
                        format='png', dpi=1200)
            # plt.show()
            plt.close(fig)
            # updating old configs
            # for latter plot
            train.to_csv(PATH + "walk-forward-results/" + "MODELSFORPLOT/" + "{}-{}_train.csv".format(output_file_name,
                                                                                                      str(cfg)))
            total_test.to_csv(
                PATH + "walk-forward-results/" + "MODELSFORPLOT/" + "{}-{}_total_test.csv".format(output_file_name,
                                                                                                  str(cfg)))
            fc_series.to_csv(
                PATH + "walk-forward-results/" + "MODELSFORPLOT/" + "{}-{}_fc_series.csv".format(output_file_name,
                                                                                                 str(cfg)))

            end = datetime.now()
            # updating old configs
            updating_old_configs_file(old_configs_file_name, cfg)
            # writing execution time for the model
            writing_model_execution_time(old_configs_file_name, end - start)
            total_exectuion_time += end - start
            writing_total_execution_time(old_configs_file_name, total_exectuion_time)
        except:
            print("\n\n\n\nError in walking forward all models\n\n\n\n")
            print("Unexpected error:", sys.exc_info()[0])

        print(output_file_name)


def walk_forward_sarima(output_file_name, config, old_configs_file_name, number_of_top_models, target_period_days,
                        days_to_test, start_date, dataset_name, exog_columns):
    with tf.device('/device:GPU:0'):
        total_test = pd.Series()
        total_predict = pd.Series()
        # creating the new folder path

        try:
            path = PATH + "walk-forward-results/" + str(config)
            print(path)
            os.mkdir(path)
        except OSError:
            print("ERROR Creation of the directory %s failed" % path)
        else:
            print("Successfully created the directory %s " % path)
        # splitting data and creating the model
        try:
            path = PATH + "walk-forward-results/" + str(config) + "/images"
            print(path)
            os.mkdir(path)
        except OSError:
            print("ERROR Creation of the directory %s failed" % path)
        else:
            print("Successfully created the directory %s " % path)
        try:
            for walking_parameter in range(1, days_to_test + 1):
                train, test, exog_train, exog_test, data = read_and_split_data(
                    target_period_days=target_period_days + walking_parameter, start_date=start_date, days_to_test=1,
                    exog_columns=exog_columns, file_name=dataset_name)
                # print(train.head) print(test.head)
                # print(train)
                model_fit, predict = run_and_save_SARIMA_model(train, test, config,
                                                               "walk-forward-results/" + str(
                                                                   config) + '/' + output_file_name + str(
                                                                   config) + "DAY" + str(walking_parameter))
                print(config, walking_parameter)
                total_test = total_test.append(test)
                total_predict = total_predict.append(predict)
                # print("test\n",type(predict))
                # print("total predict\n",len(total_predict))
            # print("total test", total_test)
            # print("total predict", total_predict)
            fig = PLT.figure(num=None, figsize=(25, 10), dpi=80, facecolor='w', edgecolor='k')
            PLT.plot(total_test.index, total_test, total_test.index, total_predict, '-')
            PLT.savefig(PATH + "walk-forward-results/" + str(config) + '/images/{}.png'.format(output_file_name))
            PLT.close(fig)

            # intra day MPE, MAE interday
            error_avg = 0
            meanError = 0
            meanRMSE = 0
            meanMSE = 0
            meanMAE = 0
            meanMAPE = 0
            meanMPE = 0
            meanR2S = 0
            data_frequency_per_day = 96
            for day in range(days_to_test):
                error_avg += abs(
                    mean_percentage_error(total_test[day * data_frequency_per_day:(day + 1) * data_frequency_per_day],
                                          total_predict[
                                          day * data_frequency_per_day:(day + 1) * data_frequency_per_day]))
                meanError += abs(
                    mean_error(total_test[day * data_frequency_per_day:(day + 1) * data_frequency_per_day],
                               total_predict[
                               day * data_frequency_per_day:(day + 1) * data_frequency_per_day]))

                meanRMSE += abs(
                    sqrt(metrics.mean_squared_error(
                        total_test[day * data_frequency_per_day:(day + 1) * data_frequency_per_day],
                        total_predict[
                        day * data_frequency_per_day:(day + 1) * data_frequency_per_day])))

                meanMSE += abs(
                    metrics.mean_squared_error(
                        total_test[day * data_frequency_per_day:(day + 1) * data_frequency_per_day],
                        total_predict[
                        day * data_frequency_per_day:(day + 1) * data_frequency_per_day]))

                meanMAE += abs(
                    metrics.mean_absolute_error(
                        total_test[day * data_frequency_per_day:(day + 1) * data_frequency_per_day],
                        total_predict[
                        day * data_frequency_per_day:(day + 1) * data_frequency_per_day]))

                meanMAPE += abs(
                    mean_absolute_percentage_error(
                        total_test[day * data_frequency_per_day:(day + 1) * data_frequency_per_day],
                        total_predict[
                        day * data_frequency_per_day:(day + 1) * data_frequency_per_day]))

                meanMPE += abs(
                    mean_percentage_error(total_test[day * data_frequency_per_day:(day + 1) * data_frequency_per_day],
                                          total_predict[
                                          day * data_frequency_per_day:(day + 1) * data_frequency_per_day]))

                meanR2S += abs(
                    metrics.r2_score(total_test[day * data_frequency_per_day:(day + 1) * data_frequency_per_day],
                                     total_predict[
                                     day * data_frequency_per_day:(day + 1) * data_frequency_per_day]))

            with open(PATH + "walk-forward-results/" + str(config) + '/{}.txt'.format(output_file_name), 'a+') as f:
                print("-----------------{}-----------------".format(str(config)), file=f)
                print("MSE", metrics.mean_squared_error(total_test, total_predict), file=f)
                print("RMSE", sqrt(metrics.mean_squared_error(total_test, total_predict)), file=f)
                print("MAE", metrics.mean_absolute_error(total_test, total_predict), file=f)
                print("MAPE", mean_absolute_percentage_error(total_test, total_predict), '%', file=f)
                print("MPE", mean_percentage_error(total_test, total_predict), '%', file=f)
                print("R2S", metrics.r2_score(total_test, total_predict), file=f)
                print("Intra Day MPE, Inter day MAE", error_avg / days_to_test, file=f)
                print("MeanError", meanError / days_to_test, file=f)
                print("------------------", file=f)
                print("meanRMSE", meanRMSE / days_to_test, file=f)
                print("meanMSE", meanMSE / days_to_test, file=f)
                print("meanMAE", meanMAE / days_to_test, file=f)
                print("meanMAPE", meanMAPE / days_to_test, file=f)
                print("meanMPE", meanMPE / days_to_test, file=f)
                print("meanR2S", meanR2S / days_to_test, file=f)

            f.close()
            return model_fit, total_test, total_predict, train
        except:
            print("\n\n\n\nError in walk forward sarima\n\n\n\n")
            print("Unexpected error:", sys.exc_info()[0])


def run_forward_all_models_sarima(output_file_name, config, old_configs_file_name, number_of_top_models, days_to_test,
                                  target_period_days, start_date, dataset_name):
    model_summaries_AIC = []
    model_summaries_MPE = []
    model_summaries_RMSE = []
    model_summaries_MAPE = []
    model_summaries_MAE = []
    model_summaries_intra_MPE = []
    data_frequency_per_day = 96  # 24 hours * 4 freq/hour
    total_exectuion_time = timedelta()

    for cfg in config:
        try:
            start = datetime.now()
            model_fit, total_test, total_predict, train = walk_forward_sarima(output_file_name=output_file_name,
                                                                              config=cfg,
                                                                              old_configs_file_name=old_configs_file_name,
                                                                              number_of_top_models=number_of_top_models,
                                                                              days_to_test=days_to_test,
                                                                              target_period_days=target_period_days,
                                                                              start_date=start_date,
                                                                              dataset_name=dataset_name,
                                                                              exog_columns=exog_columns)
        except:
            print("following model was skiped:", str(cfg))

        try:
            model_summaries_MPE = write_top_models_by_measure(model_summaries_MPE, summaryDto(
                np.abs(mean_percentage_error(total_test, total_predict)), model_fit.summary()),
                                                              number_of_top_models,
                                                              "walk-forward-results/" + output_file_name + "--MPE-")
            model_summaries_RMSE = write_top_models_by_measure(model_summaries_RMSE, summaryDto(
                sqrt(metrics.mean_squared_error(total_test, total_predict)), model_fit.summary()),
                                                               number_of_top_models,
                                                               "walk-forward-results/" + output_file_name + "--RMSE-")
            model_summaries_MAPE = write_top_models_by_measure(model_summaries_MAPE, summaryDto(
                np.abs(mean_absolute_percentage_error(total_test, total_predict)), model_fit.summary()),
                                                               number_of_top_models,
                                                               "walk-forward-results/" + output_file_name + "--MAPE-")
            model_summaries_MAE = write_top_models_by_measure(model_summaries_MAE, summaryDto(
                np.abs(metrics.mean_absolute_error(total_test, total_predict)), model_fit.summary()),
                                                              number_of_top_models,
                                                              "walk-forward-results/" + output_file_name + "--MAE-")

            # intra day MPE, MAE interday
            error_avg = 0
            for day in range(days_to_test):
                error_avg += abs(
                    mean_percentage_error(
                        total_test[day * data_frequency_per_day:(day + 1) * data_frequency_per_day],
                        total_predict[
                        day * data_frequency_per_day:(day + 1) * data_frequency_per_day]))
            model_summaries_intra_MPE = write_top_models_by_measure(model_summaries_intra_MPE,
                                                                    summaryDto(error_avg / days_to_test,
                                                                               model_fit.summary()),
                                                                    number_of_top_models,
                                                                    "walk-forward-results/" + output_file_name + "--INTRA Day MPE- INTER Day MAe-")

            orig = train

            orig.append(total_test)
            fc_series = pd.Series(total_predict, index=total_test.index)
            # lower_series = pd.Series(conf[:, 0], index=total_test.index)
            # upper_series = pd.Series(conf[:, 1], index=total_test.index)

            # Plot
            fig = plt.figure(figsize=(12, 5), dpi=100)
            plt.plot(train, label='training')
            plt.plot(total_test, label='actual')
            plt.plot(fc_series, label='forecast')
            # plt.fill_between(lower_series.index, lower_series, upper_series,
            #                 color='k', alpha=.15)
            plt.title('Forecast vs Actuals')
            plt.legend(loc='upper left', fontsize=8)
            plt.savefig(PATH + "walk-forward-results/" + str(cfg) + '/images/{}TRAINTEST.png'.format(output_file_name),
                        format='png', dpi=1200)
            # plt.show()
            plt.close(fig)
            # updating old configs
            train.to_csv(PATH + "walk-forward-results/" + "MODELSFORPLOT/" + "{}-{}_train.csv".format(output_file_name,
                                                                                                      str(cfg)))
            total_test.to_csv(
                PATH + "walk-forward-results/" + "MODELSFORPLOT/" + "{}-{}_total_test.csv".format(output_file_name,
                                                                                                  str(cfg)))
            fc_series.to_csv(
                PATH + "walk-forward-results/" + "MODELSFORPLOT/" + "{}-{}_fc_series.csv".format(output_file_name,
                                                                                                 str(cfg)))

            end = datetime.now()
            # updating old configs
            updating_old_configs_file(old_configs_file_name, cfg)
            # writing execution time for the model
            writing_model_execution_time(old_configs_file_name, end - start)
            total_exectuion_time += end - start
            writing_total_execution_time(old_configs_file_name, total_exectuion_time)
        except:
            print("\n\n\n\nError in walking forward all models\n\n\n\n")
            print("Unexpected error:", sys.exc_info()[0])

        print(output_file_name)


### FANCY PLOTS FOR THE END ####
def plot_forecasts(data_path, sarima_name, sarimax_name, arimax_name, output_file_name):
    font_size = 14  # @param {type:"integer"}
    # train_sarima = pd.read_csv(data_path + "{}_train.csv".format(sarima_name), index_col=0)
    # train_sarima.index = pd.date_range(start=train_sarima.index[0], periods=len(train_sarima), freq='15Min')

    # total_test_sarima = pd.read_csv(data_path + "{}_total_test.csv".format(sarima_name), index_col=0)
    # total_test_sarima.index = pd.date_range(start=total_test_sarima.index[0], periods=len(total_test_sarima), freq='15Min')

    fc_series_sarima = pd.read_csv(data_path + "{}_fc_series.csv".format(sarima_name), index_col=0)
    fc_series_sarima.index = pd.date_range(start=fc_series_sarima.index[0], periods=len(fc_series_sarima), freq='15Min')

    train_sarimax = pd.read_csv(data_path + "{}_train.csv".format(sarimax_name), index_col=0)
    train_sarimax.index = pd.date_range(start=train_sarimax.index[0], periods=len(train_sarimax), freq='15Min')

    total_test_sarimax = pd.read_csv(data_path + "{}_total_test.csv".format(sarimax_name), index_col=0)
    total_test_sarimax.index = pd.date_range(start=total_test_sarimax.index[0], periods=len(total_test_sarimax),
                                             freq='15Min')

    fc_series_sarimax = pd.read_csv(data_path + "{}_fc_series.csv".format(sarimax_name), index_col=0)
    fc_series_sarimax.index = pd.date_range(start=fc_series_sarimax.index[0], periods=len(fc_series_sarimax),
                                            freq='15Min')

    # train_arimax = pd.read_csv(data_path + "{}_train.csv".format(arimax_name), index_col=0)
    # train_arimax.index = pd.date_range(start=train_arimax.index[0], periods=len(train_arimax), freq='15Min')

    # total_test_arimax = pd.read_csv(data_path + "{}_total_test.csv".format(arimax_name), index_col=0)
    # total_test_arimax.index = pd.date_range(start=total_test_arimax.index[0], periods=len(total_test_arimax), freq='15Min')

    fc_series_arimax = pd.read_csv(data_path + "{}_fc_series.csv".format(arimax_name), index_col=0)
    fc_series_arimax.index = pd.date_range(start=fc_series_arimax.index[0], periods=len(fc_series_arimax), freq='15Min')

    fig = plt.figure(figsize=(12, 5), dpi=100)
    # plt.plot(train_sarimax, label='Training')
    plt.plot(total_test_sarimax, label='Actual')
    plt.plot(fc_series_sarimax, label='Forecast-SARIMAX')
    plt.plot(fc_series_sarima, label='Forecast-SARIMA')
    plt.plot(fc_series_arimax, label='Forecast-ARIMAX')
    plt.title('Forecast vs Actuals', fontsize=font_size)
    plt.legend(loc='upper left')
    plt.xlabel('Time [YYYY-MM-DD]', fontsize=font_size)
    plt.ylabel('Percentage of the Renewables [%]', fontsize=font_size)
    plt.savefig(data_path + 'PLOT-TEST-ONLY{}.png'.format(output_file_name), format='png', dpi=1200)
    plt.show()
    plt.close(fig)

    fig = plt.figure(figsize=(12, 5), dpi=100)
    plt.plot(train_sarimax, label='Training')
    plt.plot(total_test_sarimax, label='Actual')
    plt.plot(fc_series_sarimax, label='Forecast-SARIMAX')
    plt.plot(fc_series_sarima, label='Forecast-SARIMA')
    plt.plot(fc_series_arimax, label='Forecast-ARIMAX')
    plt.title('Forecast vs Actuals', fontsize=font_size)
    plt.legend(loc='upper left')
    plt.xlabel('Time [YYYY-MM-DD]', fontsize=font_size)
    plt.ylabel('Percentage of the Renewables [%]', fontsize=font_size)
    plt.savefig(data_path + 'PLOT-All{}.png'.format(output_file_name), format='png', dpi=1200)
    plt.show()
    plt.close(fig)


"""##April Wind

SARIMAX
"""

################################  CONFIG  ############################################
# splitting train and test
exog_columns = ['windspeed', 'GHI']
target_period_days = 35  # @param {type:"integer"}
number_of_top_models = 20  # @param {type:"integer"}
start_test_date = "2019-04-01 00:00:00"  # @param {type:"string"}
days_to_test = 30  # @param {type:"integer"}
dataset_name = 'Ultimate-12cities_spline_weather_entsoe_radiation_data'  # @param ['weather_entsoe_radiation_data', 'Ultimate-12cities_spline_weather_entsoe_radiation_data','Ultimate-12cities_linear_weather_entsoe_radiation_data']
old_configs_file_name = "used-configs-{}Days".format(str(target_period_days))
t_param_string = "n"  # @param ['n', 'c', 't', 'ct']
output_file_name = "THE-BEST-SARIMAX-April-windOnly-DEDICATED"  # @param {type:"string"}

output_file_name = t_param_string + "-" + output_file_name
old_configs_file_name = output_file_name + old_configs_file_name
start_date = str(datetime.strptime(start_test_date, '%Y-%m-%d %H:%M:%S') - timedelta(days=target_period_days))
######################################################################################


cfg_list = [
    # [(4, 1, 3), (2, 0, 2, 4), 'n'] #4
    [(2, 1, 3), (2, 0, 2, 4), 'n'],
    [(3, 1, 3), (2, 0, 2, 4), 'n'],
    [(1, 1, 4), (2, 0, 2, 4), 'n'],
    [(4, 1, 0), (2, 0, 2, 4), 'n'],
    [(1, 1, 3), (2, 0, 2, 4), 'n'],
    [(4, 1, 1), (2, 0, 2, 4), 'n'],
    [(2, 1, 1), (2, 0, 2, 4), 'n'],
    [(3, 1, 0), (2, 0, 2, 4), 'n'],
    [(2, 1, 2), (2, 0, 2, 4), 'n'],
    [(1, 1, 2), (2, 0, 2, 4), 'n']
]
try:
    path = PATH + "walk-forward-results"
    print(path)
    os.mkdir(path)
except OSError:
    print("ERROR Creation of the directory %s failed" % path)
else:
    print("Successfully created the directory %s " % path)

cfg_list = [str(cfg) for cfg in cfg_list]
old_configs = read_old_configs("walk-forward-results/" + old_configs_file_name)

# removing \n from each line
old_configs = [line.rstrip('\n') for line in old_configs]

# removing old configs from the current list
if (len(old_configs) > 0):
    cfg_list = list(set(cfg_list) ^ set(old_configs))

# converting from string to tuples
cfg_list = [ast.literal_eval(line) for line in cfg_list]
# cfg_list.sort(reverse=True)
# cfg_list.sort(reverse=True)
current_time = datetime.now().strftime("%d-%m-%Y %H:%M:%S")

print("Old configs size:", len(old_configs), "\nNew config size:", len(cfg_list))

run_forward_all_models(output_file_name=output_file_name + current_time, config=cfg_list,
                       old_configs_file_name="walk-forward-results/" + old_configs_file_name,
                       number_of_top_models=number_of_top_models, days_to_test=days_to_test,
                       target_period_days=target_period_days, start_date=start_date, dataset_name=dataset_name)

# cfg_list

"""SARIMA"""

################################  CONFIG  ############################################
# splitting train and test
exog_columns = ['windspeed', 'GHI']
target_period_days = 35  # @param {type:"integer"}
number_of_top_models = 20  # @param {type:"integer"}
start_test_date = "2019-04-01 00:00:00"  # @param {type:"string"}
days_to_test = 30  # @param {type:"integer"}
dataset_name = 'Ultimate-12cities_spline_weather_entsoe_radiation_data'  # @param ['weather_entsoe_radiation_data', 'Ultimate-12cities_spline_weather_entsoe_radiation_data','Ultimate-12cities_linear_weather_entsoe_radiation_data']
old_configs_file_name = "used-configs-{}Days".format(str(target_period_days))
t_param_string = "n"  # @param ['n', 'c', 't', 'ct']
output_file_name = "THE-BEST-SARIMA-April"  # @param {type:"string"}

output_file_name = t_param_string + "-" + output_file_name
old_configs_file_name = output_file_name + old_configs_file_name
start_date = str(datetime.strptime(start_test_date, '%Y-%m-%d %H:%M:%S') - timedelta(days=target_period_days))
######################################################################################


cfg_list = [
    [(4, 1, 4), (2, 0, 2, 4), 'n']  # 9

]
try:
    path = PATH + "walk-forward-results"
    print(path)
    os.mkdir(path)
except OSError:
    print("ERROR Creation of the directory %s failed" % path)
else:
    print("Successfully created the directory %s " % path)

cfg_list = [str(cfg) for cfg in cfg_list]
old_configs = read_old_configs("walk-forward-results/" + old_configs_file_name)

# removing \n from each line
old_configs = [line.rstrip('\n') for line in old_configs]

# removing old configs from the current list
if (len(old_configs) > 0):
    cfg_list = list(set(cfg_list) ^ set(old_configs))

# converting from string to tuples
cfg_list = [ast.literal_eval(line) for line in cfg_list]
# cfg_list.sort(reverse=True)
# cfg_list.sort(reverse=True)
current_time = datetime.now().strftime("%d-%m-%Y %H:%M:%S")

print("Old configs size:", len(old_configs), "\nNew config size:", len(cfg_list))

run_forward_all_models_sarima(output_file_name=output_file_name + current_time, config=cfg_list,
                              old_configs_file_name="walk-forward-results/" + old_configs_file_name,
                              number_of_top_models=number_of_top_models, days_to_test=days_to_test,
                              target_period_days=target_period_days, start_date=start_date, dataset_name=dataset_name)

# cfg_list

"""ARIMAX

"""

################################  CONFIG  ############################################
# splitting train and test
exog_columns = ['windspeed', 'GHI']
target_period_days = 35  # @param {type:"integer"}
number_of_top_models = 20  # @param {type:"integer"}
start_test_date = "2019-04-01 00:00:00"  # @param {type:"string"}
days_to_test = 30  # @param {type:"integer"}
dataset_name = 'Ultimate-12cities_spline_weather_entsoe_radiation_data'  # @param ['weather_entsoe_radiation_data', 'Ultimate-12cities_spline_weather_entsoe_radiation_data','Ultimate-12cities_linear_weather_entsoe_radiation_data']
old_configs_file_name = "used-configs-{}Days".format(str(target_period_days))
t_param_string = "n"  # @param ['n', 'c', 't', 'ct']
output_file_name = "THE-BEST-ARIMAX-April-windOnlyP"  # @param {type:"string"}

output_file_name = t_param_string + "-" + output_file_name
old_configs_file_name = output_file_name + old_configs_file_name
start_date = str(datetime.strptime(start_test_date, '%Y-%m-%d %H:%M:%S') - timedelta(days=target_period_days))
######################################################################################


cfg_list = [
    [(4, 1, 4), (0, 0, 0, 0), 'n']  # 2
]
try:
    path = PATH + "walk-forward-results"
    print(path)
    os.mkdir(path)
except OSError:
    print("ERROR Creation of the directory %s failed" % path)
else:
    print("Successfully created the directory %s " % path)

cfg_list = [str(cfg) for cfg in cfg_list]
old_configs = read_old_configs("walk-forward-results/" + old_configs_file_name)

# removing \n from each line
old_configs = [line.rstrip('\n') for line in old_configs]

# removing old configs from the current list
if (len(old_configs) > 0):
    cfg_list = list(set(cfg_list) ^ set(old_configs))

# converting from string to tuples
cfg_list = [ast.literal_eval(line) for line in cfg_list]
# cfg_list.sort(reverse=True)
# cfg_list.sort(reverse=True)
current_time = datetime.now().strftime("%d-%m-%Y %H:%M:%S")

print("Old configs size:", len(old_configs), "\nNew config size:", len(cfg_list))

run_forward_all_models(output_file_name=output_file_name + current_time, config=cfg_list,
                       old_configs_file_name="walk-forward-results/" + old_configs_file_name,
                       number_of_top_models=number_of_top_models, days_to_test=days_to_test,
                       target_period_days=target_period_days, start_date=start_date, dataset_name=dataset_name)

# cfg_list

sarima_name = "n-THE-BEST-ARIMAX-April-windOnly07-11-2020 13:07:35"  # @param {type:"string"}
sarimax_name = "n-THE-BEST-SARIMAX-April-windOnly07-11-2020 12:42:01"  # @param {type:"string"}
arimax_name = "n-THE-BEST-ARIMAX-April-windOnly07-11-2020 13:07:35"  # @param {type:"string"}
output_file_name = "April-BEST-PLOT"  # @param {type:"string"}

plot_forecasts(data_path=data_path, sarima_name=sarima_name, sarimax_name=sarimax_name, arimax_name=arimax_name,
               output_file_name=output_file_name)
